{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <center>PLANKTON CLASSIFICATION</center>\n<center>Student: Akiyo Worou</center>","metadata":{"id":"dGbqFg7osYlh"}},{"cell_type":"code","source":"# importation of libraries\nimport torch\nfrom torch import nn\nimport glob\nimport os\nfrom torch.utils.data import Dataset, WeightedRandomSampler\nimport torchvision\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom collections import Counter\nimport random\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nimport csv","metadata":{"id":"FPr-2VwYr-zy","execution":{"iopub.status.busy":"2021-12-16T10:50:16.775329Z","iopub.execute_input":"2021-12-16T10:50:16.776236Z","iopub.status.idle":"2021-12-16T10:50:19.496802Z","shell.execute_reply.started":"2021-12-16T10:50:16.776110Z","shell.execute_reply":"2021-12-16T10:50:19.495375Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2021-12-16T10:50:19.499097Z","iopub.execute_input":"2021-12-16T10:50:19.499397Z","iopub.status.idle":"2021-12-16T10:50:19.507736Z","shell.execute_reply.started":"2021-12-16T10:50:19.499363Z","shell.execute_reply":"2021-12-16T10:50:19.507117Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Datasets, Preprocessing and Data loading","metadata":{"id":"kSgSSLDi3UOp"}},{"cell_type":"code","source":"##\nclass SRDataset(Dataset):\n    def __init__(self,path):\n        self.folders_names = os.listdir(path)\n        self.images_path=[]\n        self.labels = []\n        self.test_images_path = []\n        self.test_labels = []\n        for subfolder_name in self.folders_names:\n            \n            subfolder_images_names = glob.glob( os.path.join(path,subfolder_name , '*.jpg')   ) \n            subfolder_images_names_train, subfolder_images_names_test =train_test_split(subfolder_images_names , test_size = 0.2)\n            \n            ## train \n            self.images_path+= subfolder_images_names_train\n            self.labels += [ int(subfolder_name[:3])  ]*len(subfolder_images_names_train) \n            \n            ## test\n            self.test_images_path +=subfolder_images_names_test\n            self.test_labels += [ int(subfolder_name[:3])  ]*len(subfolder_images_names_test) \n            \n    def __len__(self):\n        return len(self.images_path)\n    def __getitem__(self,index):\n        label_ = torch.tensor(self.labels[index])\n        im=torchvision.io.read_image(self.images_path[index])\n        im=(1/255)*im\n        im=transforms.Compose([\n        #transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n        transforms.Resize((64,64),interpolation=transforms.InterpolationMode.BILINEAR)\n        ])(im)\n        \n        return im,label_ \n    \n    def get_test_set(self):\n        return self.test_images_path,self.test_labels\n    def get_distribution(self):\n        return dict(Counter(self.labels))\n    def classes(self):\n        indices = [[] for i in range(len(self.get_distribution().keys()))]\n        for i in range(len(self.labels)):\n            indices[self.labels[i]].append(i)\n        return indices\n    def weights(self):\n        weights_ = [0]*len(self.labels)\n        labels_distribution = train_dataset.get_distribution()\n        sum_val = sum(labels_distribution.values())\n        for i in range(len(self.labels)):\n            weights_[i] = sum_val/labels_distribution[ self.labels[i]]\n        return weights_\n        \n\n      ","metadata":{"id":"KI8Cpgm0tAfM","execution":{"iopub.status.busy":"2021-12-16T10:50:19.508940Z","iopub.execute_input":"2021-12-16T10:50:19.509166Z","iopub.status.idle":"2021-12-16T10:50:19.522454Z","shell.execute_reply.started":"2021-12-16T10:50:19.509138Z","shell.execute_reply":"2021-12-16T10:50:19.521743Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class SREvalDataset(Dataset):\n    def __init__(self,test_images_path,test_labels):\n        self.test_images_path = test_images_path\n        self.test_labels = test_labels\n        \n    def __len__(self):\n        return len(self.test_images_path)\n    def __getitem__(self,index):\n        label_ = torch.tensor(self.test_labels[index])\n        im=torchvision.io.read_image(self.test_images_path[index])\n        im=(1/255)*im\n        im=transforms.Compose([\n        #transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n        transforms.Resize((64,64),interpolation=transforms.InterpolationMode.BILINEAR)\n        ])(im)\n        \n        return im,label_ \n    def get_distribution(self):\n        return dict(Counter(self.test_labels))\n    def classes(self):\n        indices = [[] for i in range(len(self.get_distribution().keys()))]\n        for i in range(len(self.test_labels)):\n            indices[self.test_labels[i]].append(i)\n        return indices\n    def weights(self):\n        weights_ = [0]*len(self.test_labels)\n        labels_distribution = train_dataset.get_distribution()\n        sum_val = sum(labels_distribution.values())\n        for i in range(len(self.test_labels)):\n            weights_[i] = sum_val/labels_distribution[ self.test_labels[i]]\n        return weights_","metadata":{"execution":{"iopub.status.busy":"2021-12-16T10:50:19.524275Z","iopub.execute_input":"2021-12-16T10:50:19.524935Z","iopub.status.idle":"2021-12-16T10:50:19.542126Z","shell.execute_reply.started":"2021-12-16T10:50:19.524900Z","shell.execute_reply":"2021-12-16T10:50:19.541241Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"### batch_sampler finally not used\n\nclass Sampler():\n    def __init__(self, classes):\n        self.classes = classes\n\n    def __iter__(self):\n        batches = []\n        classes = (self.classes).copy()\n        classes_size = [len(el) for el in classes]\n        m = min(classes_size)\n        classes_size_norm = [ el//m for el in classes_size ]\n        for i in range(m-1):\n            batch = []\n            for j in range(len(classes_size_norm)):\n                for k in range(classes_size_norm[j]):\n                    index = random.randint(0,len(classes[j])-1)\n                    batch.append(classes[j].pop(index))\n            batches.append(batch)\n        batches.append(  [val for sublist in classes for val in sublist] )\n        \n            \n        return iter(batches)","metadata":{"execution":{"iopub.status.busy":"2021-12-16T10:50:19.543291Z","iopub.execute_input":"2021-12-16T10:50:19.543953Z","iopub.status.idle":"2021-12-16T10:50:19.561259Z","shell.execute_reply.started":"2021-12-16T10:50:19.543920Z","shell.execute_reply":"2021-12-16T10:50:19.560297Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\ntrain_path='../input/plankton-dataset/train/train'\n#dataset = SRDataset(train_path)\n\n#dataset_size = len(dataset)\n#train_dataset, eval_dataset = torch.utils.data.random_split(dataset, [ int(dataset_size*0.7), dataset_size - int(dataset_size*0.7)])\n\ntrain_dataset = SRDataset(train_path)\n\neval_dataset = SREvalDataset( *train_dataset.get_test_set() )\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-16T10:50:19.562704Z","iopub.execute_input":"2021-12-16T10:50:19.563156Z","iopub.status.idle":"2021-12-16T10:50:39.207973Z","shell.execute_reply.started":"2021-12-16T10:50:19.563111Z","shell.execute_reply":"2021-12-16T10:50:39.207002Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"### the dataloader\n\ndef get_data_loader(dataset):\n\n    ## get the labels distributions\n    labels_distribution = dataset.get_distribution()\n\n    ## weights for sampling\n    weights =dataset.weights()\n    sampler = WeightedRandomSampler(weights,len(weights))\n\n    return torch.utils.data.dataloader.DataLoader(\n        dataset,\n        batch_size=64,\n        sampler = sampler,\n        drop_last=True,\n        pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-16T10:50:39.209129Z","iopub.execute_input":"2021-12-16T10:50:39.209394Z","iopub.status.idle":"2021-12-16T10:50:39.215026Z","shell.execute_reply.started":"2021-12-16T10:50:39.209365Z","shell.execute_reply":"2021-12-16T10:50:39.214108Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_dataloader = get_data_loader(train_dataset)\neval_dataloader = get_data_loader(eval_dataset)","metadata":{"execution":{"iopub.status.busy":"2021-12-16T10:50:39.216211Z","iopub.execute_input":"2021-12-16T10:50:39.216552Z","iopub.status.idle":"2021-12-16T10:50:39.530567Z","shell.execute_reply.started":"2021-12-16T10:50:39.216526Z","shell.execute_reply":"2021-12-16T10:50:39.529712Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"\nprint(f\" * Dataset contains {len(train_dataset)} image(s).\")\nfor _, batch in enumerate(train_dataloader, 0):\n    image, label = batch\n    #lr_image=lr_image[0, ...].mul(255).byte()\n    #hr_image=hr_image[0, ...].mul(255).byte()\n    #print(lr_image.shape)\n    #print(lr_image[0, ...].mul(255).byte().shape)\n    plt.imshow(image[0, ...].mul(255).byte().reshape(64,64),cmap='gray')\n    #torchvision.io.write_png(image[0, ...].mul(255).byte(), \"image.png\")\n    print(label)\n    break # we deliberately break after one batch as this is just a test\n","metadata":{"id":"OA89vxyb02l1","outputId":"ad26c5ba-f798-4a5d-f2bd-9a6adae37d28","execution":{"iopub.status.busy":"2021-12-16T10:50:39.532031Z","iopub.execute_input":"2021-12-16T10:50:39.532379Z","iopub.status.idle":"2021-12-16T10:50:40.676320Z","shell.execute_reply.started":"2021-12-16T10:50:39.532337Z","shell.execute_reply":"2021-12-16T10:50:40.675287Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Create  Models\n","metadata":{"id":"CL35oy0X3tTZ"}},{"cell_type":"code","source":"images_size = 64\nnb_class = 86","metadata":{"execution":{"iopub.status.busy":"2021-12-16T10:50:40.678661Z","iopub.execute_input":"2021-12-16T10:50:40.678980Z","iopub.status.idle":"2021-12-16T10:50:40.683642Z","shell.execute_reply.started":"2021-12-16T10:50:40.678944Z","shell.execute_reply":"2021-12-16T10:50:40.682357Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Model paper \n\nclass convModel(torch.nn.Module):\n    def __init__(self,interpolation='bilinear'):\n        super().__init__()\n            \n        # First convolution \n        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=images_size, kernel_size=3, stride=1, padding=0)\n        self.relu1 = nn.ReLU()\n        \n        # Max pool 1\n        self.maxpool1 = nn.MaxPool2d(kernel_size=3,stride = 2)\n     \n        # Convolution 2\n        self.cnn2 = nn.Conv2d(in_channels=images_size, out_channels=2*images_size, kernel_size=3, stride=1, padding=0)\n        self.relu2 = nn.ReLU()\n        \n        # Max pool 2\n        self.maxpool2 = nn.MaxPool2d(kernel_size=2,stride = 2)\n        \n        # Convolution 3\n        self.cnn3 = nn.Conv2d(in_channels=2*images_size, out_channels=2*images_size, kernel_size=3, stride=1, padding=0)\n        self.relu3 = nn.ReLU()\n        \n        # Max pool 3\n        self.maxpool3 = nn.MaxPool2d(kernel_size=2,stride = 2)\n        \n        # Convolution 4\n        self.cnn4 = nn.Conv2d(in_channels=2*images_size, out_channels=4*images_size, kernel_size=3, stride=1, padding=0)\n        self.relu4 = nn.ReLU()\n        \n        # Max pool 4\n        self.maxpool4 = nn.MaxPool2d(kernel_size=2,stride = 2)\n        \n        # Convolution 5\n        self.cnn5 = nn.Conv2d(in_channels=4*images_size, out_channels=4*images_size, kernel_size=3, stride=1, padding=0)\n        self.relu5 = nn.ReLU()\n        \n        # Max pool 5\n        self.maxpool5 = nn.MaxPool2d(kernel_size=2,stride = 2)\n        \n        \n        # Fully connected 1\n        self.fc1 = nn.Linear(256, 256) \n        \n        ## \n        self.dropout1 =nn.Dropout(p=0.2)\n        \n        # Fully connected 2\n        self.fc2 = nn.Linear(256, 256) \n        \n        ## \n        self.dropout2 =nn.Dropout(p=0.2)\n        \n        self.output = nn.Linear(256, nb_class) \n        \n    def forward(self, x):\n        # Convolution 1\n        out = self.cnn1(x)\n        out = self.relu1(out)\n        \n        # Max pool 1\n        out = self.maxpool1(out)\n        \n        # Convolution 2 \n        out = self.cnn2(out)\n        out = self.relu2(out)\n        \n        # Max pool 2 \n        out = self.maxpool2(out)\n        \n        # flatten\n        out = out.view(out.size(0), -1)\n        \n        # Linear function (readout)\n        out = self.fc1(out)\n        #print(out.shape)\n        return out","metadata":{"execution":{"iopub.status.busy":"2021-12-16T10:50:40.685294Z","iopub.execute_input":"2021-12-16T10:50:40.686126Z","iopub.status.idle":"2021-12-16T10:50:40.860754Z","shell.execute_reply.started":"2021-12-16T10:50:40.686090Z","shell.execute_reply":"2021-12-16T10:50:40.859341Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Model definition\n\nclass myModel(torch.nn.Module):\n    def __init__(self,interpolation='bilinear'):\n        super().__init__()\n            \n        # First convolution \n        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=images_size//2, kernel_size=5, stride=1, padding=0)\n        self.relu1 = nn.ReLU()\n        \n        # Max pool 1\n        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n     \n        # Convolution 2\n        self.cnn2 = nn.Conv2d(in_channels=images_size//2, out_channels=images_size, kernel_size=5, stride=1, padding=0)\n        self.relu2 = nn.ReLU()\n        \n        # Max pool 2\n        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n        \n        # Fully connected 1\n        self.fc1 = nn.Linear(images_size * 169, nb_class) \n    \n    def forward(self, x):\n        # Convolution 1\n        out = self.cnn1(x)\n        out = self.relu1(out)\n        \n        # Max pool 1\n        out = self.maxpool1(out)\n        \n        # Convolution 2 \n        out = self.cnn2(out)\n        out = self.relu2(out)\n        \n        # Max pool 2 \n        out = self.maxpool2(out)\n        \n        # flatten\n        out = out.view(out.size(0), -1)\n        \n        # Linear function (readout)\n        out = self.fc1(out)\n        #print(out.shape)\n        return out","metadata":{"execution":{"iopub.status.busy":"2021-12-16T10:50:40.863248Z","iopub.execute_input":"2021-12-16T10:50:40.863626Z","iopub.status.idle":"2021-12-16T10:50:40.879878Z","shell.execute_reply.started":"2021-12-16T10:50:40.863586Z","shell.execute_reply":"2021-12-16T10:50:40.879006Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Model parameters check\n#model=myModel()\nmodel = convModel()\nmodel.to(device)\nnum_params=0\nfor param in model.parameters():\n    num_params+=param.numel()\nprint(num_params)","metadata":{"id":"w197RLuOBxHS","outputId":"25abb4e5-f4fa-4f4b-930e-d5fc604989cc","execution":{"iopub.status.busy":"2021-12-16T10:50:40.882818Z","iopub.execute_input":"2021-12-16T10:50:40.883535Z","iopub.status.idle":"2021-12-16T10:50:40.915909Z","shell.execute_reply.started":"2021-12-16T10:50:40.883499Z","shell.execute_reply":"2021-12-16T10:50:40.915300Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Task 3 - Implement the Training Loop","metadata":{"id":"rZo7v0iUEEFY"}},{"cell_type":"code","source":"### Not implemented yet\nclass F1_Loss(nn.Module):\n    def __init__(self, epsilon=1e-7):\n        super().__init__()\n        self.epsilon = epsilon\n        \n    def forward(self, y_pred, y_true,):\n        \n        assert y_pred.ndim == 2\n        assert y_true.ndim == 1\n        print(y_pred.shape,y_true.shape)\n        return f1_score(y_pred,y_true,average='macro')\n        ","metadata":{"execution":{"iopub.status.busy":"2021-12-16T10:50:40.916966Z","iopub.execute_input":"2021-12-16T10:50:40.917322Z","iopub.status.idle":"2021-12-16T10:50:40.923020Z","shell.execute_reply.started":"2021-12-16T10:50:40.917293Z","shell.execute_reply":"2021-12-16T10:50:40.922006Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Some usefuls elements to setup\nsaving_path='myModel.pth'\n\nnumber_of_epoch = 20\n\n\nloss_function = torch.nn.CrossEntropyLoss() ## F1_Loss()\nlearning_rate=1e-4\n\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),\n    lr=learning_rate)","metadata":{"id":"h5nvMCxdEbri","execution":{"iopub.status.busy":"2021-12-16T10:50:40.924919Z","iopub.execute_input":"2021-12-16T10:50:40.925266Z","iopub.status.idle":"2021-12-16T10:50:40.937601Z","shell.execute_reply.started":"2021-12-16T10:50:40.925207Z","shell.execute_reply":"2021-12-16T10:50:40.936438Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model =myModel()\n\n# checkpoint = torch.load('../input/model-saved/myModel.pth')\n# model.load_state_dict(checkpoint['model_state_dict'])\n\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-12-16T10:50:40.938992Z","iopub.execute_input":"2021-12-16T10:50:40.939355Z","iopub.status.idle":"2021-12-16T10:50:40.963378Z","shell.execute_reply.started":"2021-12-16T10:50:40.939313Z","shell.execute_reply":"2021-12-16T10:50:40.962350Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def train_model(model,saving_path,learning_rate=0.0001,DEBUG  = False):\n    \n    Loss_list=[]\n    eval_loss_list=[] \n    train_score_list = []\n    eval_score_list =[]\n    \n    for epoch in range(number_of_epoch):\n        Global_loss=0.0\n        train_score = 0.0\n        test_score = 0.0\n        n_train = 0\n        for images, labels in train_dataloader:\n            images, labels = images.to(device), labels.to(device)\n            # reset the gradient\n            optimizer.zero_grad()\n            # forward pass through the model\n            labels_prediction = model(images)\n            \n            # compute the loss\n            loss = loss_function(labels_prediction, labels)\n            # adding up\n            Global_loss+=loss.item()\n            # backpropagation\n            loss.backward()\n            # update the model parameters\n            optimizer.step()\n            \n            ## scoring\n            train_score += f1_score ( torch.max(labels_prediction,1)[1].cpu().data.numpy(), labels.cpu().data.numpy(),average='macro' )\n            n_train+=1\n            if DEBUG:\n                break\n            # Evaluation on the test \n        with torch.no_grad():\n            n=0\n            eval_loss=0\n            for  images_test,labels_test in eval_dataloader:\n                images_test, labels_test = images_test.to(device), labels_test.to(device)\n                # forward pass through the model\n                labels_prediction = model(images_test)\n\n                eval_loss+=loss_function(labels_prediction, labels_test).item()\n                \n                test_score += f1_score ( torch.max(labels_prediction,1)[1].cpu().data.numpy(), labels_test.cpu().data.numpy(),average='macro' )\n                n+=1\n                if DEBUG:\n                    break\n                \n            eval_loss_list.append(eval_loss/n)\n            eval_score_list.append(test_score/n)\n            \n        \n         # log the metrics, images, etc\n        Global_loss/=n_train\n        Loss_list.append(Global_loss)\n        train_score_list.append(train_score/n_train)\n        print('epoch : ', epoch +1 ,'---> train loss : ',Global_loss ,' ---> eval loss : ',eval_loss/n , ' ---> train score : ',train_score/n_train, ' ---> test score : ',test_score/n )\n        \n        # saving state\n        if not DEBUG:\n            torch.save({\n                    'epoch': epoch,\n                    'model_state_dict': model.state_dict(),\n                    'optimizer_state_dict': optimizer.state_dict(),\n                    'train_score':  train_score_list,\n                    'test_score' :  eval_score_list,\n                    'eval_loss': eval_loss_list,\n                    'loss': Loss_list}, saving_path)\n    \n    fig = plt.figure(figsize=(20,15))\n    fig.subplots_adjust(hspace=0.4, wspace=0.4)\n\n    ax2 = fig.add_subplot(2, 2, 1)\n    ax2.plot(Loss_list)\n    ax2.set_title('Train Loss')\n\n    ax3 = fig.add_subplot(2, 2, 2)\n    ax3.plot(eval_loss_list)\n    ax3.set_title('Eval Loss')\n\n    ax4 = fig.add_subplot(2, 2, 3)\n    ax4.plot(train_score_list)\n    ax4.set_title('Train score')\n\n    ax5 = fig.add_subplot(2, 2, 4)\n    ax5.plot( eval_loss_list )\n    ax5.set_title('Eval Score')\n\n    plt.show()","metadata":{"id":"7T-okjbw5vBe","execution":{"iopub.status.busy":"2021-12-16T10:50:40.964545Z","iopub.execute_input":"2021-12-16T10:50:40.965199Z","iopub.status.idle":"2021-12-16T10:50:40.978967Z","shell.execute_reply.started":"2021-12-16T10:50:40.965166Z","shell.execute_reply":"2021-12-16T10:50:40.978291Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_model(model,saving_path,DEBUG=False)","metadata":{"id":"gUE6N23fD27f","outputId":"a6790bee-fe74-4f29-a357-8df120068ce4","execution":{"iopub.status.busy":"2021-12-16T10:50:40.979943Z","iopub.execute_input":"2021-12-16T10:50:40.980480Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SRTestDataset(Dataset):\n    def __init__(self,test_path):\n        self.test_images_path = glob.glob( os.path.join(test_path , '*.jpg')   )\n    def __len__(self):\n        return len(self.test_images_path)\n    def __getitem__(self,index):\n        im_name = self.test_images_path[index].split('/')[-1]\n        im=torchvision.io.read_image(self.test_images_path[index])\n        im=(1/255)*im\n        im=transforms.Compose([\n        #transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n        transforms.Resize((64,64),interpolation=transforms.InterpolationMode.BILINEAR)\n        ])(im)\n        \n        return im,im_name","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## predictions\n\ndef make_predictions(test_path,DEBUG=False):\n    test_dataset = SRTestDataset(test_path)\n    test_predictions ={ 'imgname': [], 'label':[]}\n    \n    test_dataloader = torch.utils.data.dataloader.DataLoader(\n        test_dataset,\n        batch_size=64)\n    with torch.no_grad():\n        for  images_test,images_name in test_dataloader:\n            images_test = images_test.to(device)\n            labels_prediction = torch.max(model(images_test),1)[1].cpu().data.numpy()\n                \n            for i in range(len(images_name)):\n                test_predictions['label'].append(labels_prediction[i])\n                test_predictions['imgname'].append(images_name[i])\n                if DEBUG:\n                    print( images_name[i], labels_prediction[i])\n            if DEBUG:\n                break\n    ### saving the result \n    with open(\"predictions.csv\", \"w\") as outfile:\n        writer = csv.writer(outfile)\n        writer.writerow(test_predictions.keys())\n        writer.writerows(zip(*test_predictions.values()))\n        \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_path = '../input/plankton-dataset/test/test/imgs' \nmake_predictions(test_path,DEBUG=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}